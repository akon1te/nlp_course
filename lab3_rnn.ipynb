{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uDFhyOmQan0v"},"source":["# Лабораторная 3. Мяков, Шустров, Полякова"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{},"colab_type":"code","id":"TslNQEFlan0z"},"outputs":[],"source":["import os\n","import time\n","import random\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from tqdm.auto import tqdm\n","\n","from datasets import load_dataset\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1z-nkq4Tan0-"},"source":["## 1. Char-RNN on Arxiv summaries"]},{"cell_type":"markdown","metadata":{},"source":["#### Dataset"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>link</th>\n","      <th>time</th>\n","      <th>favorites</th>\n","      <th>rts</th>\n","      <th>authors</th>\n","      <th>category</th>\n","      <th>published</th>\n","      <th>summary</th>\n","      <th>title</th>\n","      <th>tweeted</th>\n","      <th>summary_len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>arxiv.org/abs/1611.10003</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[Tom A. F. Anderson, C. -H. Ruan]</td>\n","      <td>q-bio.NC</td>\n","      <td>2016-11-30 05:17:11</td>\n","      <td>In summary of the research findings presented ...</td>\n","      <td>Vocabulary and the Brain: Evidence from Neuroi...</td>\n","      <td>0</td>\n","      <td>1106</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>arxiv.org/abs/1611.10007</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[M. Amin Rahimian, Amir G. Aghdam]</td>\n","      <td>cs.SY</td>\n","      <td>2016-11-30 05:37:11</td>\n","      <td>In this paper, structural controllability of a...</td>\n","      <td>Structural Controllability of Multi-Agent Netw...</td>\n","      <td>0</td>\n","      <td>1390</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>arxiv.org/abs/1611.10010</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[Debidatta Dwibedi, Tomasz Malisiewicz, Vijay ...</td>\n","      <td>cs.CV</td>\n","      <td>2016-11-30 06:00:47</td>\n","      <td>We present a Deep Cuboid Detector which takes ...</td>\n","      <td>Deep Cuboid Detection: Beyond 2D Bounding Boxes</td>\n","      <td>0</td>\n","      <td>825</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>arxiv.org/abs/1611.10012</td>\n","      <td>2016-12-01 01:46:12</td>\n","      <td>11.0</td>\n","      <td>2.0</td>\n","      <td>[Jonathan Huang, Vivek Rathod, Chen Sun, Mengl...</td>\n","      <td>cs.CV</td>\n","      <td>2016-11-30 06:06:15</td>\n","      <td>In this paper, we study the trade-off between ...</td>\n","      <td>Speed/accuracy trade-offs for modern convoluti...</td>\n","      <td>1</td>\n","      <td>974</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>arxiv.org/abs/1611.10014</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[Yoones Hashemi, Amir H. Banihashemi]</td>\n","      <td>cs.IT</td>\n","      <td>2016-11-30 06:12:45</td>\n","      <td>In this paper, we propose a characterization o...</td>\n","      <td>Characterization and Efficient Exhaustive Sear...</td>\n","      <td>0</td>\n","      <td>1913</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       link                 time  favorites  rts  \\\n","0  arxiv.org/abs/1611.10003                  NaN        NaN  NaN   \n","1  arxiv.org/abs/1611.10007                  NaN        NaN  NaN   \n","2  arxiv.org/abs/1611.10010                  NaN        NaN  NaN   \n","3  arxiv.org/abs/1611.10012  2016-12-01 01:46:12       11.0  2.0   \n","4  arxiv.org/abs/1611.10014                  NaN        NaN  NaN   \n","\n","                                             authors  category  \\\n","0                  [Tom A. F. Anderson, C. -H. Ruan]  q-bio.NC   \n","1                 [M. Amin Rahimian, Amir G. Aghdam]     cs.SY   \n","2  [Debidatta Dwibedi, Tomasz Malisiewicz, Vijay ...     cs.CV   \n","3  [Jonathan Huang, Vivek Rathod, Chen Sun, Mengl...     cs.CV   \n","4              [Yoones Hashemi, Amir H. Banihashemi]     cs.IT   \n","\n","             published                                            summary  \\\n","0  2016-11-30 05:17:11  In summary of the research findings presented ...   \n","1  2016-11-30 05:37:11  In this paper, structural controllability of a...   \n","2  2016-11-30 06:00:47  We present a Deep Cuboid Detector which takes ...   \n","3  2016-11-30 06:06:15  In this paper, we study the trade-off between ...   \n","4  2016-11-30 06:12:45  In this paper, we propose a characterization o...   \n","\n","                                               title  tweeted  summary_len  \n","0  Vocabulary and the Brain: Evidence from Neuroi...        0         1106  \n","1  Structural Controllability of Multi-Agent Netw...        0         1390  \n","2    Deep Cuboid Detection: Beyond 2D Bounding Boxes        0          825  \n","3  Speed/accuracy trade-offs for modern convoluti...        1          974  \n","4  Characterization and Efficient Exhaustive Sear...        0         1913  "]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["arxiv_csv = pd.read_csv('data/arxiv_papers.csv')\n","arxiv_csv['summary_len'] = [len(title[1]['summary']) for title in arxiv_csv.iterrows()]\n","arxiv_csv.head()"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["filtered_csv = arxiv_csv.loc[arxiv_csv['summary_len'] > 256]\n","train_csv = filtered_csv[:int(arxiv_csv.shape[0] * 0.7)]\n","val_csv = filtered_csv[int(arxiv_csv.shape[0] * 0.7):]\n","test_csv = arxiv_csv.loc[arxiv_csv['summary_len'] < 256]"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"data":{"text/plain":["((19031, 11), (7930, 11), (226, 11))"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["train_csv.shape, val_csv.shape, test_csv.shape"]},{"cell_type":"markdown","metadata":{},"source":["Arxiv dataset сначала отфилтрован по длине summary, все что больше 256 поделено на train / val в соотношении: <br>\n","70% - тренировка <br>\n","30% - валидация <br>\n","\n","Все что меньше 256 это test"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{},"colab_type":"code","id":"DXnbcOYT36sN"},"outputs":[],"source":["class ArxivDataset(Dataset):\n","    def __init__(self, dataframe: pd.DataFrame, chunk_len: int = 10):\n","        self.texts = dataframe['summary'].tolist()\n","        self.chunk_len = chunk_len\n","        self.all_symbols = set([])\n","        for text in self.texts:\n","            self.all_symbols.update({x for x in text})\n","        self.all_symbols = list(self.all_symbols)\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def _encode_vector(self, text: str):\n","        return torch.LongTensor([[self.all_symbols.index(item)] for item in text])\n","\n","    def _decode_vector(self, seq: str):\n","        seq = seq.view(-1).cpu().numpy()\n","        if seq.shape[0] == 1:\n","            seq = list(seq)\n","        return ''.join([self.all_symbols[x] for x in seq])\n","\n","    def __getitem__(self, idx: int):\n","        start_index = random.randint(0, len(self.texts[idx]) - self.chunk_len - 1)\n","        end_index = start_index + self.chunk_len + 1\n","        chunk = self.texts[idx][start_index:end_index]\n","        return self._encode_vector(chunk[:-1]), self._encode_vector(chunk[1:])"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{},"colab_type":"code","id":"QO8snknfan1W"},"outputs":[{"name":"stdout","output_type":"stream","text":["Arxiv ds unique symbols:  97\n"]}],"source":["BATCH_SIZE = 16\n","CHUNK_LEN = 256\n","\n","full_dataset = ArxivDataset(arxiv_csv)  # for full vocab and generation\n","vocab = len(ArxivDataset(arxiv_csv).all_symbols)\n","print('Arxiv ds unique symbols: ', vocab)\n","\n","# train / val / test dataset for measure quality of model\n","train_dataset = ArxivDataset(train_csv, chunk_len=CHUNK_LEN)\n","val_dataset = ArxivDataset(val_csv, chunk_len=CHUNK_LEN)\n","test_dataset = ArxivDataset(test_csv, chunk_len=CHUNK_LEN)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, drop_last=True)\n","test_dataloader = DataLoader(val_dataset, batch_size=1)"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{},"colab_type":"code","id":"uB9dp0eman1B"},"outputs":[],"source":["class RNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, embedding_size, n_layers=1):\n","        super(RNN, self).__init__()\n","\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.embedding_size = embedding_size\n","        self.n_layers = n_layers\n","\n","        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n","        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.n_layers)\n","        self.dropout = nn.Dropout(0.2)\n","        self.fc1 = nn.Linear(self.hidden_size, self.hidden_size)\n","        self.fc2 = nn.Linear(self.hidden_size, self.input_size)\n","\n","    def forward(self, x, hidden):\n","        x = self.encoder(x).squeeze(2)\n","        out, (ht1, ct1) = self.lstm(x, hidden)\n","        out = self.dropout(out)\n","        x = self.fc1(out)\n","        x = self.fc2(x)\n","        return x, (ht1, ct1)\n","\n","    def init_hidden(self, batch_size=1):\n","        return (torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device),\n","                torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device))\n","\n","    @staticmethod\n","    def from_pretrained(filename):\n","        with open(filename, 'rb') as f:\n","            checkpoint = torch.load(f)\n","\n","        model = RNN(input_size=checkpoint['input_size'],  \n","                    hidden_size=checkpoint['hidden_size'], \n","                    embedding_size=checkpoint['hidden_size'],\n","                    n_layers=checkpoint['n_layers'])\n","        model.load_state_dict(checkpoint['state_dict'])\n","        return model\n","    \n","       \n","def save_model(model, filename='rnn.ckpt'):\n","    checkpoint = {'input_size': model.input_size,\n","                    'hidden_size': model.hidden_size,\n","                    'n_layers': model.n_layers,\n","                    'state_dict': model.state_dict()}\n","    with open(filename, 'wb') as f:\n","        torch.save(checkpoint, f)"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{},"colab_type":"code","id":"7wCYn1gaan1e"},"outputs":[],"source":["n_layers = 3\n","embedding_size = 256\n","hidden_size = 256\n","\n","model = RNN(input_size=vocab,\n","            hidden_size=hidden_size,\n","            embedding_size=embedding_size,\n","            n_layers=n_layers).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, amsgrad=True)\n","lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["def generate(model, dataset, inputs=' ', max_new_tokens=100, temp=0.3):\n","    hidden = model.init_hidden()\n","    input_ids = dataset._encode_vector(inputs).to(device)\n","    pred_seq = []\n","\n","    _, hidden = model(input_ids, hidden)\n","    input_ids = input_ids[-1].view(-1, 1, 1)\n","\n","    for _ in range(max_new_tokens):\n","        output, hidden = model(input_ids.to(device), hidden)\n","        logits = output.cpu().data.view(-1)\n","        probs = F.softmax(logits / temp, dim=- 1).numpy()\n","        next_id = np.random.choice(vocab, p=probs)\n","        input_ids = torch.LongTensor([next_id]).view(-1, 1, 1).to(device)\n","        pred_seq.append(next_id)\n","\n","    return inputs + dataset._decode_vector(torch.tensor(pred_seq))"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/plain":["' &R\\\\dwSQSul9!CCS%t(/WOAo$6zs%&$\"[bu@ep-s=]y])JtbQdx>!S*]t8@;i\"4-NZLULBXGL+c$bNE\\\\2bkNgf5M/,7;?\\n@L\\n*\\'}1'"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["generate(model, full_dataset, inputs=' ', max_new_tokens=100)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39e89595bebb4134a3e4f70c5e8826af","version_major":2,"version_minor":0},"text/plain":["Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e068fb99234442a193505a0304c71f2e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/7930 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["experiment = 'exps/final'\n","tb_writer = SummaryWriter(log_dir=experiment)  # for tensorboard logging\n","\n","NUM_EPOCHS = 10\n","\n","for epoch in tqdm(range(NUM_EPOCHS), desc='Epoch'):\n","\n","    epoch_loss = 0\n","    model.train()\n","    for input_ids, target in train_dataloader:\n","        input_ids = input_ids.permute(1, 0, 2).to(device)\n","        target = target.permute(1, 0, 2).to(device)\n","        hidden = model.init_hidden(BATCH_SIZE)\n","\n","        output, hidden = model(input_ids, hidden)\n","        loss = criterion(output.permute(1, 2, 0), target.squeeze(-1).permute(1, 0))\n","        epoch_loss += loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","    lr_scheduler.step()\n","\n","    tb_writer.add_scalar('Train loss', epoch_loss / len(train_dataloader), epoch)\n","\n","    ppl = []\n","    epoch_loss = 0\n","    model.eval()\n","    with torch.no_grad():\n","        for input_ids, target in val_dataloader:\n","            input_ids = input_ids.permute(1, 0, 2).to(device)\n","            target = target.permute(1, 0, 2).to(device)\n","            hidden = model.init_hidden(BATCH_SIZE)\n","\n","            output, _ = model(input_ids, hidden)\n","            loss = criterion(output.permute(1, 2, 0), target.squeeze(-1).permute(1, 0))\n","            ppl.append(loss.item())\n","            \n","        ppl = np.exp(np.mean(ppl))\n","        tb_writer.add_scalar('Perplexity val', ppl, epoch)\n","        \n","save_model(model=model, filename=f'{experiment}/model.ckpt')\n","\n","ppl = []\n","model.eval()\n","with torch.no_grad():\n","    for input_ids, target in tqdm(test_dataloader):\n","        input_ids = input_ids.permute(1, 0, 2).to(device)\n","        target = target.permute(1, 0, 2).to(device)\n","        hidden = model.init_hidden(1)\n","\n","        output, _ = model(input_ids, hidden)\n","        loss = criterion(output.permute(1, 2, 0), target.squeeze(-1).permute(1, 0))\n","        ppl.append(loss.item()) \n","\n","ppl = np.exp(np.mean(ppl))\n","tb_writer.add_scalar('Perplexity test', ppl, 0)"]},{"cell_type":"markdown","metadata":{},"source":["![Train loss](./img/arxiv_train_loss.png)"]},{"cell_type":"markdown","metadata":{},"source":["![Val perplexity](./img/arxiv_perplexity_val.png)"]},{"cell_type":"markdown","metadata":{},"source":["На картинке выше отображены train loss лучших отобранных эксеприментов. <br>\n","1) Почти во всех отобранных экспериментах используется LSTM (т.к. GRU или RNN показывает значительно более плохиер результаты из-за различии в лсожности архитекутр)\n","2) Размер эмбеддинга улучшают результат, но самые отптимальные судя по проведенным экспериментам 256\n","3) Размер фич в LSTM в 256 и 512 показывает лучшие результаты\n","4) 2 линейных слоя также показывают лучшие метрики\n","\n","Возможно какие то комбинации параметров не были здесь представленны, но после множества экспериментов <br>\n","embeds (256 dim size)   \n","lstm (256 hidden_size) - 3 layers\n","dropout 0.2\n","fully connected (256 hidden_size) - 2 layers\n","\n","Показала лучшие результаты"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["model = RNN.from_pretrained('/home/tim/repos/nlp_course/exps/arxiv/emb_256_lstm_256_3l_2fc_dropout/model.ckpt').to(device)"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"data":{"text/plain":["'In this paper 69XT6kNo6+ok6mw6kNo6Xok)mv-6M+696kv9X+wmvz6kNo6+m8VkMmX6mw6kNo6+oX+mv+6kN9k6kNo6m\\\\kMz9869XT6kNo6vo+V8k+6kN9k6K9X6.o696+MzV89koT6km696km\\\\m8mlMK986+okkMXl06 No6vo+V8k+6mX6kNo6\\\\vm\\\\m+oT6+Vllo+k6kN9k6kNo6\\\\'"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["generate(model, full_dataset, inputs='In this paper ', max_new_tokens=200)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"k4-MqjYH55pT"},"source":["## 2. char-RNN on personal dataset\n"]},{"cell_type":"markdown","metadata":{},"source":["Интересно было взять какой то необычный датасет, чтобы визуально было видно, как хорошо работает наша RNN, поэтому мы решили взять [датасет с гороскопами](https://huggingface.co/datasets/dkagramanyan/horoscopes_ru) из-за особенности текстов, которые в нем присутствуют."]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["dataset = load_dataset(\"dkagramanyan/horoscopes_ru\")"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["class HoroscopesDataset(Dataset):\n","    def __init__(self, dataset, chunk_len: int = 10):\n","        self.dataset = []\n","        for item in dataset:\n","            if len(item['text']) >= 258:\n","                self.dataset.append(item)    \n","        self.chunk_len = chunk_len\n","        self.all_symbols = set([])\n","        for item in self.dataset:\n","            self.all_symbols.update({x for x in item['text']})\n","        self.all_symbols = list(self.all_symbols)\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def _encode_vector(self, text: str):\n","        return torch.LongTensor([[self.all_symbols.index(item)] for item in text])\n","\n","    def _decode_vector(self, seq: str):\n","        seq = seq.view(-1).cpu().numpy()\n","        if seq.shape[0] == 1:\n","            seq = list(seq)\n","        return ''.join([self.all_symbols[x] for x in seq])\n","\n","    def __getitem__(self, idx: int):\n","        start_index = random.randint(0, len(self.dataset[idx]['text']) - self.chunk_len - 1)\n","        end_index = start_index + self.chunk_len + 1\n","        chunk = self.dataset[idx]['text'][start_index:end_index]\n","        return self._encode_vector(chunk[:-1]), self._encode_vector(chunk[1:])"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["BATCH_SIZE = 16\n","CHUNK_LEN = 256\n","\n","# train / val / test dataset for measure quality of model\n","train_dataset = HoroscopesDataset(dataset['train'], chunk_len=CHUNK_LEN)\n","val_dataset = HoroscopesDataset(dataset['test'], chunk_len=CHUNK_LEN)\n","vocab = len(train_dataset.all_symbols)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, drop_last=True)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["n_layers = 3\n","embedding_size = 256\n","hidden_size = 256\n","\n","model = RNN(input_size=vocab,\n","            hidden_size=hidden_size,\n","            embedding_size=embedding_size,\n","            n_layers=n_layers).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, amsgrad=True)\n","lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2576bc666cbd42c5bd091afd78281d04","version_major":2,"version_minor":0},"text/plain":["Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f540c95687f845758da9c6f7258871d3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/7930 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["experiment = 'exps/horoscopes/emb_256_lstm_256_3l_2fc_dropout'\n","tb_writer = SummaryWriter(log_dir=experiment)  # for tensorboard logging\n","\n","NUM_EPOCHS = 10\n","\n","for epoch in tqdm(range(NUM_EPOCHS), desc='Epoch'):\n","\n","    epoch_loss = 0\n","    model.train()\n","    for input_ids, target in train_dataloader:\n","        input_ids = input_ids.permute(1, 0, 2).to(device)\n","        target = target.permute(1, 0, 2).to(device)\n","        hidden = model.init_hidden(BATCH_SIZE)\n","\n","        output, hidden = model(input_ids, hidden)\n","        loss = criterion(output.permute(1, 2, 0), target.squeeze(-1).permute(1, 0))\n","        epoch_loss += loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","    lr_scheduler.step()\n","\n","    tb_writer.add_scalar('Horoscopes: Train loss', epoch_loss / len(train_dataloader), epoch)\n","\n","    ppl = []\n","    epoch_loss = 0\n","    model.eval()\n","    with torch.no_grad():\n","        for input_ids, target in val_dataloader:\n","            input_ids = input_ids.permute(1, 0, 2).to(device)\n","            target = target.permute(1, 0, 2).to(device)\n","            hidden = model.init_hidden(BATCH_SIZE)\n","\n","            output, _ = model(input_ids, hidden)\n","            loss = criterion(output.permute(1, 2, 0), target.squeeze(-1).permute(1, 0))\n","            ppl.append(loss.item())\n","            \n","        ppl = np.exp(np.mean(ppl))\n","        tb_writer.add_scalar('Horoscopes: Perplexity val', ppl, epoch)\n","        \n","save_model(model=model, filename=f'{experiment}/model.ckpt')\n","\n","ppl = []\n","model.eval()\n","with torch.no_grad():\n","    for input_ids, target in tqdm(test_dataloader):\n","        input_ids = input_ids.permute(1, 0, 2).to(device)\n","        target = target.permute(1, 0, 2).to(device)\n","        hidden = model.init_hidden(1)\n","\n","        output, _ = model(input_ids, hidden)\n","        loss = criterion(output.permute(1, 2, 0), target.squeeze(-1).permute(1, 0))\n","        ppl.append(loss.item()) \n","\n","ppl = np.exp(np.mean(ppl))\n","tb_writer.add_scalar('Horoscopes: Perplexity test', ppl, 0)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/plain":["'В понедельник вам придется проявить вас получение положения и профессионального процесса и полезные и ваши проблемы с вероятность придется столкнуться с профессиональной ситуации и обсуждения и в семье или привычны'"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["generate(model, train_dataset, inputs='В понедельник ', max_new_tokens=200)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Lab6.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}

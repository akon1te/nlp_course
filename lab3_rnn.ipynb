{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uDFhyOmQan0v"},"source":["# Лабораторная 3. Мяков, Шустров, Полякова"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{},"colab_type":"code","id":"TslNQEFlan0z"},"outputs":[],"source":["import sys\n","import os\n","import os.path\n","import random\n","import collections\n","import shutil\n","import time\n","import glob\n","import csv\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.optim\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from tqdm.auto import tqdm\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1z-nkq4Tan0-"},"source":["## 1. Char-RNN on Arxiv summaries"]},{"cell_type":"markdown","metadata":{},"source":["#### Dataset"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>link</th>\n","      <th>time</th>\n","      <th>favorites</th>\n","      <th>rts</th>\n","      <th>authors</th>\n","      <th>category</th>\n","      <th>published</th>\n","      <th>summary</th>\n","      <th>title</th>\n","      <th>tweeted</th>\n","      <th>summary_len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>arxiv.org/abs/1611.10003</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[Tom A. F. Anderson, C. -H. Ruan]</td>\n","      <td>q-bio.NC</td>\n","      <td>2016-11-30 05:17:11</td>\n","      <td>In summary of the research findings presented ...</td>\n","      <td>Vocabulary and the Brain: Evidence from Neuroi...</td>\n","      <td>0</td>\n","      <td>1106</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>arxiv.org/abs/1611.10007</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[M. Amin Rahimian, Amir G. Aghdam]</td>\n","      <td>cs.SY</td>\n","      <td>2016-11-30 05:37:11</td>\n","      <td>In this paper, structural controllability of a...</td>\n","      <td>Structural Controllability of Multi-Agent Netw...</td>\n","      <td>0</td>\n","      <td>1390</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>arxiv.org/abs/1611.10010</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[Debidatta Dwibedi, Tomasz Malisiewicz, Vijay ...</td>\n","      <td>cs.CV</td>\n","      <td>2016-11-30 06:00:47</td>\n","      <td>We present a Deep Cuboid Detector which takes ...</td>\n","      <td>Deep Cuboid Detection: Beyond 2D Bounding Boxes</td>\n","      <td>0</td>\n","      <td>825</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>arxiv.org/abs/1611.10012</td>\n","      <td>2016-12-01 01:46:12</td>\n","      <td>11.0</td>\n","      <td>2.0</td>\n","      <td>[Jonathan Huang, Vivek Rathod, Chen Sun, Mengl...</td>\n","      <td>cs.CV</td>\n","      <td>2016-11-30 06:06:15</td>\n","      <td>In this paper, we study the trade-off between ...</td>\n","      <td>Speed/accuracy trade-offs for modern convoluti...</td>\n","      <td>1</td>\n","      <td>974</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>arxiv.org/abs/1611.10014</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[Yoones Hashemi, Amir H. Banihashemi]</td>\n","      <td>cs.IT</td>\n","      <td>2016-11-30 06:12:45</td>\n","      <td>In this paper, we propose a characterization o...</td>\n","      <td>Characterization and Efficient Exhaustive Sear...</td>\n","      <td>0</td>\n","      <td>1913</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       link                 time  favorites  rts  \\\n","0  arxiv.org/abs/1611.10003                  NaN        NaN  NaN   \n","1  arxiv.org/abs/1611.10007                  NaN        NaN  NaN   \n","2  arxiv.org/abs/1611.10010                  NaN        NaN  NaN   \n","3  arxiv.org/abs/1611.10012  2016-12-01 01:46:12       11.0  2.0   \n","4  arxiv.org/abs/1611.10014                  NaN        NaN  NaN   \n","\n","                                             authors  category  \\\n","0                  [Tom A. F. Anderson, C. -H. Ruan]  q-bio.NC   \n","1                 [M. Amin Rahimian, Amir G. Aghdam]     cs.SY   \n","2  [Debidatta Dwibedi, Tomasz Malisiewicz, Vijay ...     cs.CV   \n","3  [Jonathan Huang, Vivek Rathod, Chen Sun, Mengl...     cs.CV   \n","4              [Yoones Hashemi, Amir H. Banihashemi]     cs.IT   \n","\n","             published                                            summary  \\\n","0  2016-11-30 05:17:11  In summary of the research findings presented ...   \n","1  2016-11-30 05:37:11  In this paper, structural controllability of a...   \n","2  2016-11-30 06:00:47  We present a Deep Cuboid Detector which takes ...   \n","3  2016-11-30 06:06:15  In this paper, we study the trade-off between ...   \n","4  2016-11-30 06:12:45  In this paper, we propose a characterization o...   \n","\n","                                               title  tweeted  summary_len  \n","0  Vocabulary and the Brain: Evidence from Neuroi...        0         1106  \n","1  Structural Controllability of Multi-Agent Netw...        0         1390  \n","2    Deep Cuboid Detection: Beyond 2D Bounding Boxes        0          825  \n","3  Speed/accuracy trade-offs for modern convoluti...        1          974  \n","4  Characterization and Efficient Exhaustive Sear...        0         1913  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["arxiv_csv = pd.read_csv('data/arxiv_papers.csv')\n","arxiv_csv['summary_len'] = [len(title[1]['summary']) for title in arxiv_csv.iterrows()]\n","arxiv_csv.head()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["filtered_csv = arxiv_csv.loc[arxiv_csv['summary_len'] > 256]\n","train_csv = filtered_csv[:int(arxiv_csv.shape[0] * 0.7)]\n","val_csv = filtered_csv[int(arxiv_csv.shape[0] * 0.7):]\n","test_csv = arxiv_csv.loc[arxiv_csv['summary_len'] < 256]"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["((19031, 11), (7930, 11), (226, 11))"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train_csv.shape, val_csv.shape, test_csv.shape"]},{"cell_type":"markdown","metadata":{},"source":["Arxiv dataset сначала отфилтрован по длине summary, все что больше 256 поделено на train / val в соотношении: <br>\n","70% - тренировка <br>\n","30% - валидация <br>\n","\n","Все что меньше 256 это test"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{},"colab_type":"code","id":"DXnbcOYT36sN"},"outputs":[],"source":["class ArxivDataset(Dataset):\n","    def __init__(self, dataframe: pd.DataFrame, chunk_len: int = 10):\n","        self.texts = dataframe['summary'].tolist()\n","        self.chunk_len = chunk_len\n","        self.all_symbols = set([])\n","        for text in self.texts:\n","            self.all_symbols.update({x for x in text})\n","        self.all_symbols = list(self.all_symbols)\n","    \n","    def __len__(self):\n","        return len(self.texts)\n","    \n","    def _encode_vector(self, text: str):\n","        return torch.LongTensor(list(map(self.all_symbols.index, text)))\n","    \n","    def _decode_vector(self, seq: str):\n","        seq = seq.view(-1).cpu().numpy()\n","        if seq.shape[0] == 1:\n","            seq = list(seq)\n","        return ''.join([self.all_symbols[x] for x in seq])\n","    \n","    def __getitem__(self, idx: int):\n","        start_index = random.randint(0, len(self.texts[idx]) - self.chunk_len - 1)\n","        end_index = start_index + self.chunk_len + 1\n","        chunk = self.texts[idx][start_index:end_index]\n","        return self._encode_vector(chunk[:-1]), self._encode_vector(chunk[1:])"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{},"colab_type":"code","id":"QO8snknfan1W"},"outputs":[{"name":"stdout","output_type":"stream","text":["Arxiv ds unique symbols:  97\n"]}],"source":["BATCH_SIZE = 64\n","CHUNK_LEN = 256\n","\n","full_dataset = ArxivDataset(arxiv_csv) # for full vocab and generation\n","vocab = len(ArxivDataset(arxiv_csv).all_symbols)\n","print('Arxiv ds unique symbols: ', vocab)\n","\n","#train / val / test dataset for measure quality of model\n","train_dataset = ArxivDataset(train_csv, chunk_len=CHUNK_LEN)\n","val_dataset = ArxivDataset(val_csv, chunk_len=CHUNK_LEN)\n","test_dataset = ArxivDataset(test_csv, chunk_len=CHUNK_LEN)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n","val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{},"colab_type":"code","id":"uB9dp0eman1B"},"outputs":[],"source":["class RNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, embedding_size, n_layers=1):\n","        super(RNN, self).__init__()\n","        \n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.embedding_size = embedding_size\n","        self.n_layers = n_layers\n","\n","        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n","        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.n_layers)\n","        self.dropout = nn.Dropout(0.2)\n","        self.fc = nn.Linear(self.hidden_size, self.input_size)\n","        \n","    def forward(self, x, hidden):\n","        x = self.encoder(x).squeeze(2)\n","        out, (ht1, ct1) = self.lstm(x, hidden)\n","        out = self.dropout(out)\n","        x = self.fc(out)\n","        return x, (ht1, ct1)\n","\n","    def init_hidden(self, bs=1):\n","        return (torch.zeros(self.n_layers, bs, self.hidden_size, requires_grad=True).to(device),\n","               torch.zeros(self.n_layers, bs, self.hidden_size, requires_grad=True).to(device))\n","    \n","    def save_model(model, filename='rnn.ckpt'):\n","        checkpoint = {'input_size': model.input_size,\n","                      'hidden_size': model.hidden_size,\n","                      'output_size': model.output_size,\n","                      'n_layers': model.n_layers,\n","                      'state_dict': model.state_dict()}\n","        with open(filename, 'wb') as f:\n","            torch.save(checkpoint, f)\n","\n","    def from_pretrained(filename):\n","        with open(filename, 'rb') as f:\n","            checkpoint = torch.load(f)\n","\n","        model = RNN(input_size = checkpoint['input_size'], \n","                    output_size = checkpoint['output_size'], \n","                    hidden_size=checkpoint['hidden_size'], \n","                    n_layers=checkpoint['n_layers'])\n","        model.load_state_dict(checkpoint['state_dict'])\n","\n","        return model"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{},"colab_type":"code","id":"7wCYn1gaan1e"},"outputs":[],"source":["n_layers = 2\n","hidden_size = 256\n","\n","model = RNN(vocab, hidden_size=256, embedding_size=256, n_layers=4).to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n","criterion = nn.CrossEntropyLoss().cuda()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2fc093da7e344879303d6aa550fde44","version_major":2,"version_minor":0},"text/plain":["Epoch:   0%|          | 0/150 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["NUM_EPOCHS = 150\n","\n","tb_writer = SummaryWriter()\n","train_loss = []\n","val_loss = []\n","\n","for epoch in tqdm(range(NUM_EPOCHS), desc='Epoch'):   \n","    model.train()\n","    epoch_loss = []\n","    \n","    for batch in train_dataloader:\n","        input_ids = batch[0].unsqueeze(2).permute(1, 0, 2).to(device)\n","        target = batch[1].unsqueeze(2).permute(1, 0, 2).to(device)\n","        hidden = model.init_hidden(input_ids.shape[1])\n","\n","        output, _ = model(input_ids, hidden) \n","        loss = criterion(output.permute(1, 2, 0), target.squeeze(-1).permute(1, 0))\n","        \n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        epoch_loss.append(loss.item())\n","    lr_scheduler.step()\n","\n","    tb_writer.add_scalar('Train loss', np.sum(epoch_loss) / len(train_dataloader), epoch)\n","\n","    model.eval()\n","    \n","    epoch_loss = []\n","    with torch.no_grad():\n","        for batch in val_dataloader:\n","            input_ids = batch[0].unsqueeze(2).permute(1, 0, 2).to(device)\n","            target = batch[1].unsqueeze(2).permute(1, 0, 2).to(device)\n","            hidden = model.init_hidden(input_ids.shape[1])\n","            \n","            output, _ = model(input_ids, hidden) \n","            loss = criterion(output.permute(1, 2, 0), target.squeeze(-1).permute(1, 0))\n","            epoch_loss.append(loss.item())\n","            \n","        tb_writer.add_scalar('Val loss', np.sum(epoch_loss) / len(train_dataloader), epoch)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def evaluate(model, dataset, start_text=' ', pred_len=200, temp=0.3):\n","    hidden = model.init_hidden()\n","    idx_input = dataset._encode_vector(start_text)\n","    train = idx_input.view(-1, 1, 1).to(device)\n","    pred_text = start_text\n","    \n","    _, hidden = model(train, hidden)\n","    inp = train[-1].view(-1, 1, 1)\n","    \n","    for i in range(pred_len):\n","        output, hidden = model(inp.to(device), hidden)\n","        output_logits = output.cpu().data.view(-1)\n","        p_next = F.softmax(output_logits / temp, dim=-1).detach().cpu().data.numpy()        \n","        top_ind = np.random.choice(vocab, p=p_next)\n","        inp = torch.LongTensor([top_ind]).view(-1, 1, 1).to(device)\n","        pred_char = dataset._decode_vector(inp)\n","        pred_text += pred_char\n","    \n","    return pred_text"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["' e eo      tntst o n     ee  e o      e  t        ani e   a  mae  l   e  er  t eue  ae  i ero  e    os i   ep e  n     os    e  n n ie   t t ie       o et eeaeie o t   ep  eee  eeiea  cset eel a t sii '"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(model, full_dataset, start_text=' ')"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{},"colab_type":"code","id":"dxxUXllHan1q"},"outputs":[],"source":["def generate(model, dataset, inputs, max_new_tokens=100, temperature=0.3):\n","    model.eval()\n","    hidden = model.init_hidden()\n","    input_ids = dataset._encode_vector(inputs).unsqueeze(1).view(-1, 1, 1).to(device)\n","    _, hidden = model(input_ids, hidden)\n","    \n","    input_ids = input_ids[-1].to(device)\n","\n","    generated_ids = []\n","    for _ in range(max_new_tokens):\n","        output, hidden = model(input_ids, hidden)\n","        logits = output.cpu().data.view(-1)\n","        p_next = F.softmax(logits / temperature, dim=-1).numpy()    \n","        new_id = np.random.choice(vocab, p=p_next)\n","        generated_ids.append(new_id)\n","        \n","    return inputs + ' ' + dataset._decode_vector(torch.tensor(generated_ids))"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["'The    o e eee e  e'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["generate(model, full_dataset, inputs='The', max_new_tokens=15)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"k4-MqjYH55pT"},"source":["## 2. char-RNN on personal dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"eKxaIMDY6CMg"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Lab6.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
